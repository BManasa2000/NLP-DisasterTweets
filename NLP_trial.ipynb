{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_trial.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "kmw4hixEUwPv",
        "i85CRlzpIUYE",
        "MDtAKu7nmycE",
        "XJeMzlS5RCvq",
        "o7v7q4d4f57W",
        "QKvGgIJ7vFXq",
        "O9NAzLHj1evk",
        "1mqw50DxAJw5",
        "eDgkAePNRIIK",
        "o9hnemolUwZX",
        "U4lPEFVH38qw",
        "BkThYXEr5EAx",
        "gxoBHQVCAOei",
        "wyJPvvP9K03Y",
        "U6IHJgSMJ2_8",
        "Fe3kZEzH6aGn",
        "oQBtFMKS8LCo",
        "ygAiYLfUGg5r",
        "QEQar84SPduy",
        "X5O-OODRPUhZ",
        "6YGS7ZqpVXkr",
        "Agnmdw0QuHSh",
        "4mmNJCst2yOR"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__tF6FeR4u0i"
      },
      "source": [
        "PS: Had made changes to LDA2Vec. Did not work.\n",
        "TF-IDF with LSTM, XGBoost not working. Didn't do for SVM. If I did, then didn't check if it was working."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbyekQwe7eij",
        "outputId": "ce336748-dca9-47ca-a022-7035d93a07f0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ak5nkKC8_ok"
      },
      "source": [
        "# GLOVE_VECTORS_FILE = \"/content/gdrive/MyDrive/NLP_Project/glove.twitter.27B.50d.txt\"\n",
        "GLOVE_VECTORS_FILE = \"/content/gdrive/MyDrive/NLP_Project/glove.twitter.27B.100d.txt\"\n",
        "TRAIN_FILE = \"/content/gdrive/MyDrive/NLP_Project/train.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYEH2PE2Xiyj"
      },
      "source": [
        "# Using embeddings for MLP\n",
        "import sklearn\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from tensorflow.keras.models import load_model\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "import pickle\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "import string\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "tknzr = TweetTokenizer()\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(patience=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ka9NKF2EBiDx"
      },
      "source": [
        "df = pd.read_csv(TRAIN_FILE)\n",
        "# df_test = pd.read_csv(TEST_FILE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoQP9UdgHVrt"
      },
      "source": [
        "#dropping columns that will not be used\n",
        "df = df.drop(columns = ['id','keyword','location'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZVJMftYPBaL",
        "outputId": "1d8ab8b1-fb7e-4b21-ae1a-81586d65b0b9"
      },
      "source": [
        "print(df.columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['text', 'target'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmw4hixEUwPv"
      },
      "source": [
        "### **PRE PROCESSING THE TRAINING DATA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYP7J38wHrsV"
      },
      "source": [
        "df_clean = df\n",
        "#converting to lower case\n",
        "df_clean['text'] = df.text.str.lower()\n",
        "#removing duplicate tweets\n",
        "df_clean.drop_duplicates(subset='text',inplace=True)\n",
        "# for internet links starting with http/s and hashtags and user mentions using regular exp\n",
        "df_clean.text = df_clean.text.apply(lambda x: re.sub(r'(?:\\@|\\#|https?:\\/\\/)\\S+', '', x))\n",
        " # for intenet links starting with www\n",
        "df_clean.text = df_clean.text.apply(lambda x: re.sub(r\"www\\.[a-z]?\\.?(com)+|[a-z]+\\.(com)\", '', x))\n",
        "#removing digits\n",
        "df_clean.text = df_clean.text.apply(lambda x: re.sub(r'[0-9]', '', x))\n",
        "#removing punctuations\n",
        "df_clean.text = df_clean.text.apply(lambda x: re.sub(r'[\\(\\)\\-\\:\\;\\!\\.\\,\\?\\\\\\/\\*\\&\\^\\%\\$\\#\\@\\\"\\<\\>\\+\\=\\-\\_\\[\\]\\{\\}\\~\\`\\']', ' ', x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnONnnLpGLkb"
      },
      "source": [
        "# tokenizing\n",
        "df_clean['tokens'] = df_clean['text'].apply(tknzr.tokenize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8_LTM30byRg",
        "outputId": "8bb509f5-f965-4dbd-c229-7f6bacf256b8"
      },
      "source": [
        "df_clean.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['text', 'target', 'tokens'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5wg1Dtp5oCR"
      },
      "source": [
        "#shuffling the rows in the data frame\n",
        "df_clean = df_clean.sample(frac = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i85CRlzpIUYE"
      },
      "source": [
        "## **I) WORD2VEC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhZJFjMHyp1S"
      },
      "source": [
        "# import gensim, import word2vec, fit on your tokens "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAbq-PSbW6IQ"
      },
      "source": [
        "# from gensim.test.utils import common_texts\n",
        "from gensim.models import Word2Vec\n",
        "model_word2vec = Word2Vec(sentences=df_clean['tokens'], size=100, window=5, min_count=1, workers=4)\n",
        "model_word2vec.save(\"word2vec.model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdN3fEt0XYtY"
      },
      "source": [
        "#model['razed']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeY3xoQgbjxB"
      },
      "source": [
        "max_features = 30000 # total number of words in vocabulary \n",
        "max_len = 100  # maximum input token length\n",
        "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
        "tokenizer.fit_on_texts(df_clean['text'])\n",
        "\n",
        "X = tokenizer.texts_to_sequences(df_clean['text'])\n",
        "X = pad_sequences(X, maxlen = 100)\n",
        "Y = pd.get_dummies(df_clean['target']).values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vuMKObxdLal",
        "outputId": "b0c498c2-b233-4ec0-c606-98878781b70b"
      },
      "source": [
        "v_size = len(tokenizer.word_index) + 1\n",
        "embedding_matrix = np.zeros((v_size, 100))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "  if word not in model_word2vec.wv.vocab:\n",
        "    embedding_vector = np.zeros(100)\n",
        "  else:\n",
        "    embedding_vector = model_word2vec[word]\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix[index] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  import sys\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GO9QWJdwePEb"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, stratify=Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDtAKu7nmycE"
      },
      "source": [
        "#I)A) LDA2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_3nhX-gk5-r"
      },
      "source": [
        "# from gensim.test.utils import common_texts\n",
        "from gensim.models import LdaModel\n",
        "from gensim.corpora.dictionary import Dictionary\n",
        "\n",
        "common_text = df_clean['tokens']\n",
        "\n",
        "# Create a corpus from a list of texts\n",
        "common_dictionary = Dictionary(df_clean['tokens'])\n",
        "common_corpus = [common_dictionary.doc2bow(text) for text in common_text]\n",
        "\n",
        "# Train the model on the corpus.\n",
        "num_topics = 15\n",
        "lda = LdaModel(common_corpus, num_topics=num_topics)\n",
        "\n",
        "# print(common_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njxpBHKeniea"
      },
      "source": [
        "def LDA_topics(model, num_topics):\n",
        "    word_dict = {};\n",
        "    for i in range(num_topics):\n",
        "        words = model_word2vec.show_topic(i, topn = 10);\n",
        "        word_dict['Words of Topic ' + '{:02d}'.format(i+1)] = [i[0] for i in words];\n",
        "    return pd.DataFrame(word_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXxYoWCymwD-"
      },
      "source": [
        "LDA_topics(lda, num_topics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyrIozeFmEJ9",
        "outputId": "c5b1d09f-d641-4145-fcb8-bd23a4d7cc6c"
      },
      "source": [
        "from gensim.models import CoherenceModel\n",
        "coherence_using_lda2vec = CoherenceModel(model=lda, texts=common_text, dictionary=common_dictionary, coherence='c_v')\n",
        "coherence = coherence_using_lda2vec.get_coherence()\n",
        "print('Coherence Score: ', round(coherence, 3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coherence Score:  0.302\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9CCuHTwY4WY"
      },
      "source": [
        "svd_matrix = lda.fit(common_corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0H2DX3OYsWW",
        "outputId": "a170bd5c-0bfa-4b90-8465-93c2415a457c"
      },
      "source": [
        "print(type(coherence_using_lda2vec))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'gensim.models.coherencemodel.CoherenceModel'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x58DLUSGYphn"
      },
      "source": [
        "X_lr = \n",
        "Y_lr = df_clean['target']\n",
        "X_lr_train, X_lr_test, Y_lr_train, Y_lr_test = train_test_split(X_lr, Y_lr, test_size = 0.2, random_state = 1)\n",
        "clf = LogisticRegression(random_state=0).fit(X_lr_train, Y_lr_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJeMzlS5RCvq"
      },
      "source": [
        "# I)B) MLP WITH WORD2VEC EMBEDDINGS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTx3K6wLdv3X"
      },
      "source": [
        "maxlen = 100\n",
        "model_word2vec_mlp = tf.keras.Sequential([\n",
        "         tf.keras.layers.Embedding(v_size, 100, weights=[embedding_matrix],input_length = maxlen),\n",
        "         tf.keras.layers.Flatten(),\n",
        "         tf.keras.layers.Dense(500,activation='relu'),\n",
        "         tf.keras.layers.Dense(2,activation='softmax')                  \n",
        "        ])\n",
        "model_word2vec_mlp.compile(loss = \"binary_crossentropy\",optimizer = 'adam',metrics = ['accuracy'])\n",
        "model_word2vec_mlp.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeO_WyZqeh9B"
      },
      "source": [
        "model_word2vec_mlp.fit(X_train, Y_train, epochs = 3, verbose = 1, validation_split=0.1,  callbacks=[early_stopping])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rXG3uZWe04E"
      },
      "source": [
        "model_word2vec_mlp.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcxLwxTghIHi"
      },
      "source": [
        "y_pred = model_word2vec_mlp.predict(X_test)\n",
        "y_pred_single = [np.argmax(i) for i in y_pred]\n",
        "y_test_single = [np.argmax(i) for i in Y_test]\n",
        "print(sklearn.metrics.classification_report(y_test_single, y_pred_single))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7v7q4d4f57W"
      },
      "source": [
        "# I)C) LSTM with Word2Vec embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kwy2dY4f8Yt",
        "outputId": "524f7bf2-30b4-4f51-b0f7-1fd2d5130c46"
      },
      "source": [
        "maxlen = 100\n",
        "model_word2vec_lstm = tf.keras.Sequential([\n",
        "         tf.keras.layers.Embedding(v_size, 100, weights=[embedding_matrix],input_length = maxlen),\n",
        "         tf.keras.layers.LSTM(128),\n",
        "         tf.keras.layers.Dense(2,activation='softmax')                  \n",
        "        ])\n",
        "model_word2vec_lstm.compile(loss = \"binary_crossentropy\",optimizer = 'adam',metrics = ['accuracy'])\n",
        "model_word2vec_lstm.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_9 (Embedding)     (None, 100, 100)          1324300   \n",
            "                                                                 \n",
            " lstm_13 (LSTM)              (None, 128)               117248    \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,441,806\n",
            "Trainable params: 1,441,806\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFDkWda9gLWk",
        "outputId": "0c6e3c4a-73f8-42f5-c912-5b570c39eecb"
      },
      "source": [
        "model_word2vec_lstm.fit(X_train, Y_train, epochs = 3, verbose = 1, validation_split=0.1, callbacks=[early_stopping])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "169/169 [==============================] - 28s 150ms/step - loss: 0.6516 - accuracy: 0.6080 - val_loss: 0.5112 - val_accuracy: 0.7687\n",
            "Epoch 2/3\n",
            "169/169 [==============================] - 25s 150ms/step - loss: 0.3872 - accuracy: 0.8374 - val_loss: 0.4563 - val_accuracy: 0.7953\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa60a0ec690>"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEg5vWJVgOLF",
        "outputId": "79980894-37cc-4bf8-a654-64eb78fc42d2"
      },
      "source": [
        "model_word2vec_lstm.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47/47 [==============================] - 2s 37ms/step - loss: 0.4515 - accuracy: 0.7948\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.45150139927864075, 0.7948034405708313]"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aR3PZSR4hCtJ",
        "outputId": "48586c20-d0d9-4c27-d1f0-cb1aedd63519"
      },
      "source": [
        "y_pred = model_word2vec_lstm.predict(X_test)\n",
        "y_pred_single = [np.argmax(i) for i in y_pred]\n",
        "y_test_single = [np.argmax(i) for i in Y_test]\n",
        "print(sklearn.metrics.classification_report(y_test_single, y_pred_single))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.82      0.82       861\n",
            "           1       0.76      0.77      0.76       640\n",
            "\n",
            "    accuracy                           0.79      1501\n",
            "   macro avg       0.79      0.79      0.79      1501\n",
            "weighted avg       0.80      0.79      0.79      1501\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKvGgIJ7vFXq"
      },
      "source": [
        "##I)D) XGBOOST with WORD2VEC Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjIeGzn3vS9t",
        "outputId": "56832118-3517-4498-ad1d-b8424813c866"
      },
      "source": [
        "xgb_input = []\n",
        "for i in range(len(df_clean['tokens'])):\n",
        "  temp = np.zeros(100, dtype=float)\n",
        "  for j in range(len(df_clean.iloc[i]['tokens'])):\n",
        "    temp += np.array(model_word2vec[df_clean.iloc[i]['tokens'][j]])\n",
        "  temp /= len(df_clean.iloc[i]['tokens'])\n",
        "  xgb_input.append(temp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1tIyKQnvUN-",
        "outputId": "bdf137b1-f081-4fb4-d9b8-647bcfdc0578"
      },
      "source": [
        "xgb_input = np.array(xgb_input)\n",
        "print(xgb_input.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7502, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_r5thGZvZ4X"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(xgb_input, df_clean['target'], stratify=df_clean['target'],test_size=0.2, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmD_4R9Nvbq3",
        "outputId": "dd68758c-ec65-4bf1-8a4a-f1c2e3bea545"
      },
      "source": [
        "cross_val_score(XGBClassifier(), xgb_input, df_clean['target'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.6835443 , 0.69686875, 0.67666667, 0.68      , 0.69066667])"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XejMWVB27L9o",
        "outputId": "8a9ca649-a54a-4439-a23c-dce036f4181d"
      },
      "source": [
        "cross_val_score(XGBClassifier(), xgb_input, df_clean['target']).mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6855492782589385"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9NAzLHj1evk"
      },
      "source": [
        "##I)E) SVM with WORD2VEC Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fR6NqaIXQFdv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07a39345-aaa6-467b-93f1-dbde0c47eaf1"
      },
      "source": [
        "xgb_input = []\n",
        "for i in range(len(df_clean['tokens'])):\n",
        "  temp = np.zeros(100, dtype=float)\n",
        "  for j in range(len(df_clean.iloc[i]['tokens'])):\n",
        "    temp += np.array(model_word2vec[df_clean.iloc[i]['tokens'][j]])\n",
        "  temp /= len(df_clean.iloc[i]['tokens'])\n",
        "  xgb_input.append(temp)\n",
        "\n",
        "xgb_input = np.array(xgb_input)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(xgb_input, df_clean['target'], stratify=df_clean['target'],test_size=0.2, random_state=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sEQ6zZJ1nSp",
        "outputId": "eed863d0-cded-43c6-cdd1-0f084f1bff8b"
      },
      "source": [
        "# Pipeline(steps=[('standardscaler', StandardScaler()),\n",
        "#                 ('svc', SVC(gamma='auto'))])\n",
        "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
        "clf.fit(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
              "                ('svc', SVC(gamma='auto'))])"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANNFkwDH12in"
      },
      "source": [
        "y_pred = clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvAFgA5z1963",
        "outputId": "bbe0a01e-e093-41a3-faa0-653b9bc181ab"
      },
      "source": [
        "print(sklearn.metrics.accuracy_score(Y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6835443037974683\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPW929Y82RXL",
        "outputId": "77e12898-90dc-43cd-a447-727a7d778266"
      },
      "source": [
        "print(sklearn.metrics.classification_report(Y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.82      0.75       861\n",
            "           1       0.67      0.50      0.57       640\n",
            "\n",
            "    accuracy                           0.68      1501\n",
            "   macro avg       0.68      0.66      0.66      1501\n",
            "weighted avg       0.68      0.68      0.67      1501\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mqw50DxAJw5"
      },
      "source": [
        "## **II) FastText**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1L7DxEeBfg_"
      },
      "source": [
        "from gensim.models import FastText\n",
        "\n",
        "model_fast = FastText(size=100, window=3, min_count=1, sentences=df_clean['tokens'], workers=10)\n",
        "model_fast.save(\"fasttext.model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iq3EIRSfE_a4"
      },
      "source": [
        "# model_fast.wv.most_similar(\"accident\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pU1KIbxGQxIU"
      },
      "source": [
        "max_features = 30000 # total number of words in vocabulary \n",
        "max_len = 100  # maximum input token length\n",
        "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
        "tokenizer.fit_on_texts(df_clean['text'])\n",
        "\n",
        "X = tokenizer.texts_to_sequences(df_clean['text'])\n",
        "X = pad_sequences(X, maxlen = 100)\n",
        "Y = pd.get_dummies(df_clean['target']).values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8orIE8VQ3B8",
        "outputId": "84e45b2b-22cf-4f5b-b3c6-020950d7c088"
      },
      "source": [
        "v_size = len(tokenizer.word_index) + 1\n",
        "embedding_matrix = np.zeros((v_size, 100))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "  if word not in model_fast.wv.vocab:\n",
        "    embedding_vector = np.zeros(100)\n",
        "  else:\n",
        "    embedding_vector = model_fast[word]\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix[index] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  import sys\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pVB9S3LRnV-"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, stratify=Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDgkAePNRIIK"
      },
      "source": [
        "## II)A) MLP with FastText embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wURrvPhlRHJm",
        "outputId": "c80ef831-ab42-4e26-f975-cd0c303b90f0"
      },
      "source": [
        "maxlen = 100\n",
        "model_fast_mlp = tf.keras.Sequential([\n",
        "         tf.keras.layers.Embedding(v_size, 100, weights=[embedding_matrix],input_length = maxlen),\n",
        "         tf.keras.layers.Flatten(),\n",
        "         tf.keras.layers.Dense(500,activation='relu'),\n",
        "         tf.keras.layers.Dense(2,activation='softmax')                  \n",
        "        ])\n",
        "model_fast_mlp.compile(loss = \"binary_crossentropy\",optimizer = 'adam',metrics = ['accuracy'])\n",
        "model_fast_mlp.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_24\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_19 (Embedding)    (None, 100, 100)          1324300   \n",
            "                                                                 \n",
            " flatten_10 (Flatten)        (None, 10000)             0         \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 500)               5000500   \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 2)                 1002      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,325,802\n",
            "Trainable params: 6,325,802\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwFU0RGoRtgl",
        "outputId": "a9c31298-82f5-4398-890e-e49703f5b1f6"
      },
      "source": [
        "model_fast_mlp.fit(X_train, Y_train, epochs = 3, verbose = 1, validation_split=0.1, callbacks=[early_stopping])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "169/169 [==============================] - 12s 69ms/step - loss: 0.6987 - accuracy: 0.5881 - val_loss: 0.6400 - val_accuracy: 0.5957\n",
            "Epoch 2/3\n",
            "169/169 [==============================] - 12s 68ms/step - loss: 0.4834 - accuracy: 0.7728 - val_loss: 0.5815 - val_accuracy: 0.6789\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa601ed9650>"
            ]
          },
          "metadata": {},
          "execution_count": 242
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19MFxXMFTuIA",
        "outputId": "72b4c96b-23c1-4f4a-e011-d8bf4103e63a"
      },
      "source": [
        "model_fast_mlp.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47/47 [==============================] - 1s 12ms/step - loss: 0.5530 - accuracy: 0.7109\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5529842376708984, 0.7108594179153442]"
            ]
          },
          "metadata": {},
          "execution_count": 243
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpYGXiNjgtdw",
        "outputId": "9bec9aa5-3a1b-41b2-cf6c-427ab72479d5"
      },
      "source": [
        "y_pred = model_fast_mlp.predict(X_test)\n",
        "y_pred_single = [np.argmax(i) for i in y_pred]\n",
        "y_test_single = [np.argmax(i) for i in Y_test]\n",
        "print(sklearn.metrics.classification_report(y_test_single, y_pred_single))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.62      0.71       861\n",
            "           1       0.62      0.83      0.71       640\n",
            "\n",
            "    accuracy                           0.71      1501\n",
            "   macro avg       0.73      0.73      0.71      1501\n",
            "weighted avg       0.74      0.71      0.71      1501\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9hnemolUwZX"
      },
      "source": [
        "## II)B) LSTM with FastText embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gSds3FsUun2",
        "outputId": "368c2023-0fa5-4e29-a699-f6956b2638f0"
      },
      "source": [
        "maxlen = 100\n",
        "model_fast_lstm = tf.keras.Sequential([\n",
        "         tf.keras.layers.Embedding(v_size, 100, weights=[embedding_matrix],input_length = maxlen),\n",
        "         tf.keras.layers.LSTM(128),\n",
        "         tf.keras.layers.Dense(2,activation='softmax')                  \n",
        "        ])\n",
        "model_fast_lstm.compile(loss = \"binary_crossentropy\",optimizer = 'adam',metrics = ['accuracy'])\n",
        "model_fast_lstm.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_20 (Embedding)    (None, 100, 100)          1324300   \n",
            "                                                                 \n",
            " lstm_19 (LSTM)              (None, 128)               117248    \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,441,806\n",
            "Trainable params: 1,441,806\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvfFQJhUVIXr",
        "outputId": "996f8ccc-ca6e-45a0-e662-80e87b9d3156"
      },
      "source": [
        "model_fast_lstm.fit(X_train, Y_train, epochs = 3, verbose = 1, validation_split=0.1, callbacks=[early_stopping])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "169/169 [==============================] - 27s 148ms/step - loss: 0.6481 - accuracy: 0.6117 - val_loss: 0.5153 - val_accuracy: 0.7587\n",
            "Epoch 2/3\n",
            "169/169 [==============================] - 25s 146ms/step - loss: 0.4330 - accuracy: 0.8144 - val_loss: 0.4993 - val_accuracy: 0.7554\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa6034f9710>"
            ]
          },
          "metadata": {},
          "execution_count": 246
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpVO2pXdVWIa",
        "outputId": "9ecfb8c4-0676-435e-c9b8-5981e7f7a240"
      },
      "source": [
        "model_fast_lstm.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47/47 [==============================] - 2s 35ms/step - loss: 0.4817 - accuracy: 0.7821\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.48170867562294006, 0.7821452617645264]"
            ]
          },
          "metadata": {},
          "execution_count": 247
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1FYMy1SYJYM",
        "outputId": "10718f9f-0511-49ae-aaee-0099c40abc9c"
      },
      "source": [
        "y_pred = model_fast_lstm.predict(X_test)\n",
        "y_pred_single = [np.argmax(i) for i in y_pred]\n",
        "y_test_single = [np.argmax(i) for i in Y_test]\n",
        "print(sklearn.metrics.classification_report(y_test_single, y_pred_single))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.79      0.81       861\n",
            "           1       0.73      0.78      0.75       640\n",
            "\n",
            "    accuracy                           0.78      1501\n",
            "   macro avg       0.78      0.78      0.78      1501\n",
            "weighted avg       0.78      0.78      0.78      1501\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlbO8ArdY7a0"
      },
      "source": [
        "# y_pred[:3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IF2RJhCYvw3",
        "outputId": "23878cb9-70fa-4048-8c3a-f14fe6a408e9"
      },
      "source": [
        "sklearn.metrics.accuracy_score(y_test_single, y_pred_single)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.782145236508994"
            ]
          },
          "metadata": {},
          "execution_count": 249
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4lPEFVH38qw"
      },
      "source": [
        "##II)C) XGBOOST with FastText Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWTLYgBC4BNz",
        "outputId": "ea359a7d-13df-49de-91c8-45e89678bdd4"
      },
      "source": [
        "xgb_input = []\n",
        "for i in range(len(df_clean['tokens'])):\n",
        "  temp = np.zeros(100, dtype=float)\n",
        "  for j in range(len(df_clean.iloc[i]['tokens'])):\n",
        "    temp += np.array(model_fast[df_clean.iloc[i]['tokens'][j]])\n",
        "  temp /= len(df_clean.iloc[i]['tokens'])\n",
        "  xgb_input.append(temp)\n",
        "\n",
        "xgb_input = np.array(xgb_input)\n",
        "# print(xgb_input.shape)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(xgb_input, df_clean['target'], stratify=df_clean['target'],test_size=0.2, random_state=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSlzQb7u5TxP",
        "outputId": "eec44785-cf49-44e8-a17b-8cb94b32c04e"
      },
      "source": [
        "cross_val_score(XGBClassifier(), xgb_input, df_clean['target'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.70486342, 0.67554963, 0.68      , 0.67933333, 0.69066667])"
            ]
          },
          "metadata": {},
          "execution_count": 252
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkThYXEr5EAx"
      },
      "source": [
        "##II)D) SVM with FastText Embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sqBDGdEP9OA"
      },
      "source": [
        "xgb_input = []\n",
        "for i in range(len(df_clean['tokens'])):\n",
        "  temp = np.zeros(100, dtype=float)\n",
        "  for j in range(len(df_clean.iloc[i]['tokens'])):\n",
        "    temp += np.array(model_fast[df_clean.iloc[i]['tokens'][j]])\n",
        "  temp /= len(df_clean.iloc[i]['tokens'])\n",
        "  xgb_input.append(temp)\n",
        "\n",
        "xgb_input = np.array(xgb_input)\n",
        "# print(xgb_input.shape)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(xgb_input, df_clean['target'], stratify=df_clean['target'],test_size=0.2, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "123RnETZ5GdQ"
      },
      "source": [
        "# Pipeline(steps=[('standardscaler', StandardScaler()),\n",
        "#                 ('svc', SVC(gamma='auto'))])\n",
        "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
        "clf.fit(X_train, Y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKxcijBR5RCG",
        "outputId": "0ea340d1-4140-4da9-935c-cdf3976910ef"
      },
      "source": [
        "print(sklearn.metrics.accuracy_score(Y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6915389740173218\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1u8kHbnt5Nt2",
        "outputId": "f554a51b-83d4-4c95-bc8c-19a410aec977"
      },
      "source": [
        "print(sklearn.metrics.classification_report(Y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.83      0.76       861\n",
            "           1       0.69      0.50      0.58       640\n",
            "\n",
            "    accuracy                           0.69      1501\n",
            "   macro avg       0.69      0.67      0.67      1501\n",
            "weighted avg       0.69      0.69      0.68      1501\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxoBHQVCAOei"
      },
      "source": [
        "## **III) GLoVE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u44HKB7HZtx9"
      },
      "source": [
        "word_to_vec_map = {}\n",
        "with open(GLOVE_VECTORS_FILE, 'r', encoding='UTF-8') as f:\n",
        "    words = set()\n",
        "    for line in f:\n",
        "      w_line = line.split()\n",
        "      curr_word = w_line[0]\n",
        "      word_to_vec_map[curr_word] = np.array(w_line[1:], dtype=np.float64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85QqjnVc-r6L"
      },
      "source": [
        "# print(word_to_vec_map['the'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCP-j00EAmuh"
      },
      "source": [
        "max_features = 30000 # total number of words in vocabulary \n",
        "max_len = 100  # maximum input token length\n",
        "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
        "tokenizer.fit_on_texts(df_clean['text'])\n",
        "\n",
        "X = tokenizer.texts_to_sequences(df_clean['text'])\n",
        "X = pad_sequences(X, maxlen = 100)\n",
        "Y = pd.get_dummies(df_clean['target']).values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2THruF1dJz_H"
      },
      "source": [
        "v_size = len(tokenizer.word_index) + 1\n",
        "embed_vector_len = word_to_vec_map['the'].shape[0]\n",
        "embedding_matrix = np.zeros((v_size, 100))\n",
        "\n",
        "for word, index in tokenizer.word_index.items():\n",
        "  embedding_vector = word_to_vec_map.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix[index, :] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8Wr5buVNSJO",
        "outputId": "443be9f5-8e98-4078-c334-04c9df757a04"
      },
      "source": [
        "# word_to_vec_map.get('the').shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjX0Bn_5KHbU"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, stratify=Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyJPvvP9K03Y"
      },
      "source": [
        "## III)A) MLP WITH GLOVE WORD EMBEDDINGS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbxpbMr-K5FO",
        "outputId": "0507570e-f068-4d77-d716-1f7be6051d23"
      },
      "source": [
        "maxlen = 100\n",
        "model_glove_mlp = tf.keras.Sequential([\n",
        "         tf.keras.layers.Embedding(v_size, 100, weights=[embedding_matrix],input_length = maxlen),\n",
        "         tf.keras.layers.Flatten(),\n",
        "         tf.keras.layers.Dense(500,activation='relu'),\n",
        "         tf.keras.layers.Dense(2,activation='softmax')                  \n",
        "        ])\n",
        "model_glove_mlp.compile(loss = \"binary_crossentropy\",optimizer = 'adam',metrics = ['accuracy'])\n",
        "model_glove_mlp.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_34\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_23 (Embedding)    (None, 100, 100)          1312600   \n",
            "                                                                 \n",
            " flatten_12 (Flatten)        (None, 10000)             0         \n",
            "                                                                 \n",
            " dense_51 (Dense)            (None, 500)               5000500   \n",
            "                                                                 \n",
            " dense_52 (Dense)            (None, 2)                 1002      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,314,102\n",
            "Trainable params: 6,314,102\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VW527GZgLSD8",
        "outputId": "3d87b0f7-5f21-4183-9f8e-90b9ade60ea1"
      },
      "source": [
        "model_glove_mlp.fit(X_train, Y_train, epochs = 3, verbose = 1, validation_split=0.1, callbacks=[early_stopping])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "169/169 [==============================] - 12s 69ms/step - loss: 0.4935 - accuracy: 0.7674 - val_loss: 0.4339 - val_accuracy: 0.8203\n",
            "Epoch 2/3\n",
            "169/169 [==============================] - 12s 69ms/step - loss: 0.3130 - accuracy: 0.8731 - val_loss: 0.4725 - val_accuracy: 0.8186\n",
            "Epoch 3/3\n",
            "169/169 [==============================] - 12s 68ms/step - loss: 0.1746 - accuracy: 0.9359 - val_loss: 0.6191 - val_accuracy: 0.8003\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa5dbde6d50>"
            ]
          },
          "metadata": {},
          "execution_count": 476
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mt5HooCzLSnu",
        "outputId": "257f2b45-4c32-4632-c742-785b754b4ad4"
      },
      "source": [
        "model_glove_mlp.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47/47 [==============================] - 1s 12ms/step - loss: 0.5988 - accuracy: 0.7935\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5988075137138367, 0.7934710383415222]"
            ]
          },
          "metadata": {},
          "execution_count": 477
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXPd-Olkh8uY",
        "outputId": "3ad068cd-3c47-426b-afe9-a5e54a79bf73"
      },
      "source": [
        "y_pred = model_glove_mlp.predict(X_test)\n",
        "y_pred_single = [np.argmax(i) for i in y_pred]\n",
        "y_test_single = [np.argmax(i) for i in Y_test]\n",
        "print(sklearn.metrics.classification_report(y_test_single, y_pred_single))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.87      0.83       861\n",
            "           1       0.80      0.69      0.74       640\n",
            "\n",
            "    accuracy                           0.79      1501\n",
            "   macro avg       0.79      0.78      0.78      1501\n",
            "weighted avg       0.79      0.79      0.79      1501\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6IHJgSMJ2_8"
      },
      "source": [
        "## III)B) LSTM WITH GLOVE WORD EMBEDDINGS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNw5jRZYDt_A",
        "outputId": "000a42d7-6ab8-48e7-b7fd-a717911204cc"
      },
      "source": [
        "maxlen = 100\n",
        "model_glove_lstm = tf.keras.Sequential([\n",
        "         tf.keras.layers.Embedding(v_size, 100, weights=[embedding_matrix],input_length = maxlen),\n",
        "         tf.keras.layers.LSTM(128),\n",
        "         tf.keras.layers.Dense(2,activation='softmax')                  \n",
        "        ])\n",
        "model_glove_lstm.compile(loss = \"binary_crossentropy\",optimizer = 'adam',metrics = ['accuracy'])\n",
        "model_glove_lstm.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_27\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_22 (Embedding)    (None, 100, 100)          1324300   \n",
            "                                                                 \n",
            " lstm_20 (LSTM)              (None, 128)               117248    \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,441,806\n",
            "Trainable params: 1,441,806\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBq0f1fbJdoX",
        "outputId": "c0324229-318f-4136-9c1c-e62967e10506"
      },
      "source": [
        "model_glove_lstm.fit(X_train, Y_train, epochs = 3, verbose = 1, validation_split=0.1, callbacks=[early_stopping])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "169/169 [==============================] - 25s 150ms/step - loss: 0.0527 - accuracy: 0.9796 - val_loss: 1.0852 - val_accuracy: 0.7504\n",
            "Epoch 2/3\n",
            "169/169 [==============================] - 25s 148ms/step - loss: 0.0443 - accuracy: 0.9802 - val_loss: 1.2219 - val_accuracy: 0.7488\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa5df676fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 289
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKV6v4-2KOTm",
        "outputId": "e56b7fc7-a63a-4325-b1a2-43dbd713e4b5"
      },
      "source": [
        "model_glove_lstm.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47/47 [==============================] - 2s 36ms/step - loss: 1.0793 - accuracy: 0.7648\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0792698860168457, 0.7648234367370605]"
            ]
          },
          "metadata": {},
          "execution_count": 290
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ha7H2cUviZnH",
        "outputId": "5cf93cd4-23cf-4d50-a4c8-635aa1cb1d42"
      },
      "source": [
        "y_pred = model_glove_lstm.predict(X_test)\n",
        "y_pred_single = [np.argmax(i) for i in y_pred]\n",
        "y_test_single = [np.argmax(i) for i in Y_test]\n",
        "print(sklearn.metrics.classification_report(y_test_single, y_pred_single))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.83      0.80       861\n",
            "           1       0.75      0.67      0.71       640\n",
            "\n",
            "    accuracy                           0.76      1501\n",
            "   macro avg       0.76      0.75      0.76      1501\n",
            "weighted avg       0.76      0.76      0.76      1501\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fe3kZEzH6aGn"
      },
      "source": [
        "##III)C) XGBOOST with GLOVE Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83AYAFFPMmPr"
      },
      "source": [
        "xgb_input = []\n",
        "for i in range(len(df_clean['tokens'])):\n",
        "  temp = np.zeros(100, dtype=float)\n",
        "  for j in range(len(df_clean.iloc[i]['tokens'])):\n",
        "    embedding_vector = word_to_vec_map.get(df_clean.iloc[i]['tokens'][j])\n",
        "    if embedding_vector is not None:\n",
        "      temp += embedding_vector\n",
        "  temp /= len(df_clean.iloc[i]['tokens'])\n",
        "  xgb_input.append(temp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DW0BJCaMPDhT"
      },
      "source": [
        "xgb_input = np.array(xgb_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoxxshXC6f4D"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(xgb_input, df_clean['target'], stratify=df_clean['target'],test_size=0.2, random_state=0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6-mHB3N6jiD",
        "outputId": "b4cfcb16-ab1f-434b-f098-1b0140508d82"
      },
      "source": [
        "cross_val_score(XGBClassifier(), xgb_input, df_clean['target'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.80946036, 0.80546302, 0.78533333, 0.798     , 0.79666667])"
            ]
          },
          "metadata": {},
          "execution_count": 298
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQBtFMKS8LCo"
      },
      "source": [
        "##III)E) SVM with GLoVE Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0NvV1Z5PcUk"
      },
      "source": [
        "xgb_input = []\n",
        "for i in range(len(df_clean['tokens'])):\n",
        "  temp = np.zeros(100, dtype=float)\n",
        "  for j in range(len(df_clean.iloc[i]['tokens'])):\n",
        "    embedding_vector = word_to_vec_map.get(df_clean.iloc[i]['tokens'][j])\n",
        "    if embedding_vector is not None:\n",
        "      temp += embedding_vector\n",
        "  temp /= len(df_clean.iloc[i]['tokens'])\n",
        "  xgb_input.append(temp)\n",
        "\n",
        "xgb_input = np.array(xgb_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fpp7TmZPeKb"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(xgb_input, df_clean['target'], stratify=df_clean['target'],test_size=0.2, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZ9gzYRi8NqY"
      },
      "source": [
        "# Pipeline(steps=[('standardscaler', StandardScaler()),\n",
        "#                 ('svc', SVC(gamma='auto'))])\n",
        "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
        "clf.fit(X_train, Y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggpx3dLy8RmL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12600a23-dcb9-483c-9a60-52392dc09d74"
      },
      "source": [
        "print(sklearn.metrics.accuracy_score(Y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8094603597601598\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyQ5PLQw8TmZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49b03e99-2cb6-4771-daf6-4585ef840e9c"
      },
      "source": [
        "print(sklearn.metrics.classification_report(Y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.90      0.84       861\n",
            "           1       0.84      0.68      0.75       640\n",
            "\n",
            "    accuracy                           0.81      1501\n",
            "   macro avg       0.82      0.79      0.80      1501\n",
            "weighted avg       0.81      0.81      0.81      1501\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygAiYLfUGg5r"
      },
      "source": [
        "##**IV) TF-IDF**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNoel9yhlUcn"
      },
      "source": [
        "df_clean_tfidf = df_clean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mL1lt4vJkT94"
      },
      "source": [
        "# removing stop words\n",
        "\n",
        "stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \n",
        "             \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\",\n",
        "             \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \n",
        "             \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\",\n",
        "             \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\",\n",
        "             \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \n",
        "             \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\",\n",
        "             \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\",\n",
        "             \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\",\n",
        "             \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\",\n",
        "             \"your\", \"yours\", \"yourself\", \"yourselves\" ]\n",
        "\n",
        "df_clean_tfidf['text'] = df_clean_tfidf['text'].apply(lambda x : ' '.join([word for word in x.split() if word not in (stopwords)]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlBVHnCyq583"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "v = TfidfVectorizer()\n",
        "x = v.fit_transform(df_clean_tfidf['text'])\n",
        "x = x.toarray()\n",
        "\n",
        "Y = pd.get_dummies(df_clean['target']).values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLowgYtLtXdk"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(x, Y, test_size = 0.1, random_state = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrBvw_zNlSeq",
        "outputId": "5d71d053-fa4f-4f91-e762-c952a2e5381b"
      },
      "source": [
        "vocab = v.get_feature_names_out()\n",
        "print(vocab[-1])\n",
        "print(vocab.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "we\n",
            "(12870,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybowB7Vkjoco"
      },
      "source": [
        "# print(X[10])\n",
        "c = 0\n",
        "for i in x:\n",
        "  for j in i:\n",
        "    if j == 1:\n",
        "      c += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMW4eykTvMLO",
        "outputId": "b5ba1061-c47b-46ad-e872-c20aca718b58"
      },
      "source": [
        "print(c)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEQar84SPduy"
      },
      "source": [
        "## IV)A) MLP WITH TF-IDF VECTORS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0bfLEtJPdP7",
        "outputId": "c3c4769a-7deb-4419-b16d-bf13f644ce25"
      },
      "source": [
        "maxlen = 100\n",
        "\n",
        "model_tfidf_mlp = tf.keras.Sequential()\n",
        "# model_tfidf_mlp.add(tf.keras.layers.Flatten())\n",
        "model_tfidf_mlp.add(tf.keras.layers.Dense(500, activation='relu'))\n",
        "model_tfidf_mlp.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
        "model_tfidf_mlp.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_tfidf_mlp.build(X_train.shape)\n",
        "model_tfidf_mlp.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (6751, 500)               6435500   \n",
            "                                                                 \n",
            " dense_9 (Dense)             (6751, 2)                 1002      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,436,502\n",
            "Trainable params: 6,436,502\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Du-WZDjoL-h",
        "outputId": "6d07f90b-a5bd-40b3-b48a-f3d07721ce75"
      },
      "source": [
        "model_tfidf_mlp.fit(X_train, Y_train, epochs = 5, verbose = 1, validation_split=0.1, callbacks=[early_stopping])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "190/190 [==============================] - 9s 47ms/step - loss: 0.5466 - accuracy: 0.7213 - val_loss: 0.4286 - val_accuracy: 0.8166\n",
            "Epoch 2/5\n",
            "190/190 [==============================] - 9s 45ms/step - loss: 0.2818 - accuracy: 0.8871 - val_loss: 0.4515 - val_accuracy: 0.8062\n",
            "Epoch 3/5\n",
            "190/190 [==============================] - 9s 45ms/step - loss: 0.1474 - accuracy: 0.9505 - val_loss: 0.5067 - val_accuracy: 0.7914\n",
            "Epoch 4/5\n",
            "190/190 [==============================] - 9s 45ms/step - loss: 0.0927 - accuracy: 0.9691 - val_loss: 0.5883 - val_accuracy: 0.7840\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fabd06ddfd0>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpAZwEvqop9X",
        "outputId": "fe598b0b-2fad-4cda-c1f4-92a6970709c2"
      },
      "source": [
        "model_tfidf_mlp.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 15ms/step - loss: 0.6846 - accuracy: 0.7577\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6846101880073547, 0.757656455039978]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oId4AWTF2_0A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce8f2ee8-0ef2-43ab-e2f8-598221f81c9d"
      },
      "source": [
        "y_pred = model_tfidf_mlp.predict(X_test)\n",
        "y_pred_single = [np.argmax(i) for i in y_pred]\n",
        "y_test_single = [np.argmax(i) for i in Y_test]\n",
        "print(sklearn.metrics.classification_report(y_test_single, y_pred_single))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.81      0.80       435\n",
            "           1       0.73      0.70      0.71       316\n",
            "\n",
            "    accuracy                           0.76       751\n",
            "   macro avg       0.76      0.75      0.75       751\n",
            "weighted avg       0.76      0.76      0.76       751\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5O-OODRPUhZ"
      },
      "source": [
        "## IV)B) LSTM WITH TF-IDF VECTORS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpbL8uLFilli",
        "outputId": "b1f9e023-6424-4e69-b944-7785769f9c77"
      },
      "source": [
        "X_train_lstm = X_train[:, :, None]\n",
        "print(X_train_lstm.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6751, 12870, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbmgj9rBLMNG"
      },
      "source": [
        "maxlen = 100\n",
        "\n",
        "model_tfidf_lstm = tf.keras.Sequential()\n",
        "# model_tfidf_lstm.add(tf.keras.layers.LSTM(100, input_shape=(None, data_dim),return_sequences=True))\n",
        "model_tfidf_lstm.add(tf.keras.layers.LSTM(units=6, input_shape = X_train_lstm.shape, return_sequences = True))\n",
        "model_tfidf_lstm.add(tf.keras.layers.LSTM(128))\n",
        "model_tfidf_lstm.add(tf.keras.layers.Dense(2,activation='softmax'))\n",
        "model_tfidf_lstm.compile(loss = \"binary_crossentropy\", optimizer = 'adam', metrics = ['accuracy'])\n",
        "model_tfidf_lstm.summary()\n",
        "\n",
        "# model = Sequential()\n",
        "# model.add(LSTM(100, input_shape=(None, data_dim),return_sequences=True))\n",
        "# model.add(Dropout(0.2))\n",
        "# model.add(LSTM(200))\n",
        "# model.add(Dropout(0.2))\n",
        "# model.add(Dense(1, activation='sigmoid'))\n",
        "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YW_FCy6COWD5"
      },
      "source": [
        "model_tfidf_lstm.fit(X_train, Y_train, epochs = 3, verbose = 1, validation_split=0.1, callbacks=[early_stopping])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvl1uUBYOtQA",
        "outputId": "0c98281c-031b-4ca0-dff6-0160d94d77d6"
      },
      "source": [
        "model_tfidf_lstm.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47/47 [==============================] - 4s 47ms/step - loss: 0.6842 - accuracy: 0.5676\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6841512322425842, 0.5676215887069702]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNQNSxuB255I"
      },
      "source": [
        "y_pred = model_tfidf_lstm.predict(X_test)\n",
        "y_pred_single = [np.argmax(i) for i in y_pred]\n",
        "y_test_single = [np.argmax(i) for i in Y_test]\n",
        "print(sklearn.metrics.classification_report(y_test_single, y_pred_single))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YGS7ZqpVXkr"
      },
      "source": [
        "## IV)C) XGBoost with TF-IDF Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYGFTvlqVhXE"
      },
      "source": [
        "# xgb_input = []\n",
        "# for i in range(len(df_clean['tokens'])):\n",
        "#   temp = np.zeros(100, dtype=float)\n",
        "#   for j in range(len(df_clean.iloc[i]['tokens'])):\n",
        "#     temp += np.array(model_fast[df_clean.iloc[i]['tokens'][j]])\n",
        "#   temp /= len(df_clean.iloc[i]['tokens'])\n",
        "#   xgb_input.append(temp)\n",
        "\n",
        "xgb_input = x\n",
        "xgb_input = np.array(xgb_input)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(xgb_input, df_clean_tfidf['target'], stratify=df_clean_tfidf['target'],test_size=0.2, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itl_VWEBXOEf"
      },
      "source": [
        "print(xgb_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2l4rEBczV7Sf"
      },
      "source": [
        "cross_val_score(XGBClassifier(), xgb_input, df_clean_tfidf['target'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Agnmdw0QuHSh"
      },
      "source": [
        "##**V) LSA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VY-SPGU8fal0",
        "outputId": "ecb9f446-7358-4c90-b005-cedffed9c86b"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.pipeline import Pipeline\n",
        "documents = df_clean['text']\n",
        "  \n",
        "# raw documents to tf-idf matrix: \n",
        "v = TfidfVectorizer()\n",
        "# x = v.fit_transform(df_clean_tfidf['text'])\n",
        "\n",
        "# SVD to reduce dimensionality: \n",
        "svd_model = TruncatedSVD(n_components=2,\n",
        "                         algorithm='randomized',\n",
        "                         n_iter=10)\n",
        "# pipeline of tf-idf + SVD, fit to and applied to documents:\n",
        "svd_transformer = Pipeline([('tfidf', v), \n",
        "                            ('svd', svd_model)])\n",
        "svd_matrix = svd_transformer.fit_transform(documents)\n",
        "\n",
        "print(svd_matrix.shape)\n",
        "# svd_matrix can later be used to compare documents, compare words, or compare queries with documents"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7502, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpRR7UjnwLu6",
        "outputId": "8d4c1d64-e08b-4272-a434-638becc31181"
      },
      "source": [
        "topic_encoded_df = pd.DataFrame(svd_matrix, columns=[\"Topic1\", \"Topic2\"])\n",
        "# topic_encoded_df[\"text\"] = df_clean['text']\n",
        "\n",
        "# print(topic_encoded_df[[\"text\", \"Topic1\", \"Topic2\"]][:5])\n",
        "\n",
        "print(topic_encoded_df.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7502, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoIQqnL-0dD-"
      },
      "source": [
        "# dictionary = vectorizer.get_feature_names()\n",
        "# print(dictionary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54QVRlar0uYr"
      },
      "source": [
        "# encoding_matrix = pd.DataFrame(svd_model.components_, index=['Topic1', 'Topic2'], columns=dictionary).T\n",
        "# print(encoding_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoHjfqsK0DiO"
      },
      "source": [
        "# encoding_matrix['Topic1'] = np.abs(encoding_matrix['Topic1']) \n",
        "# encoding_matrix['Topic2'] = np.abs(encoding_matrix['Topic2'])\n",
        "\n",
        "# encoding_matrix.sort_values('Topic1', ascending=True)\n",
        "# encoding_matrix.sort_values('Topic2', ascending=True)\n",
        "\n",
        "# print(encoding_matrix)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qar8ejDr32S2",
        "outputId": "57266ab5-1d2a-456b-fecf-a4126e0796fe"
      },
      "source": [
        "X_lr = svd_matrix\n",
        "Y_lr = df_clean['target']\n",
        "X_lr_train, X_lr_test, Y_lr_train, Y_lr_test = train_test_split(X_lr, Y_lr, test_size = 0.2, random_state = 1)\n",
        "clf = LogisticRegression(random_state=0).fit(X_lr_train, Y_lr_train)\n",
        "\n",
        "clf.predict(X_lr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 334
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdOyecx45d-m",
        "outputId": "a8658394-bd50-42b1-d478-8c736db87e6c"
      },
      "source": [
        "y_pred = clf.predict(X_lr_test)\n",
        "print(sklearn.metrics.classification_report(Y_lr_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.84      0.73       853\n",
            "           1       0.65      0.38      0.48       648\n",
            "\n",
            "    accuracy                           0.64      1501\n",
            "   macro avg       0.65      0.61      0.60      1501\n",
            "weighted avg       0.64      0.64      0.62      1501\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mmNJCst2yOR"
      },
      "source": [
        "##**VII) LDA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rm0TnexPeDWX",
        "outputId": "e28c5544-e866-4c0f-ed6f-22c3f1ddcbbc"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "v = TfidfVectorizer()\n",
        "x = v.fit_transform(df_clean_tfidf['text'])\n",
        "\n",
        "lda_model = LatentDirichletAllocation(n_components = 2, max_iter = 20, random_state = 20)\n",
        "# fit transform on model on our count vectorizer : running this will return our topics\n",
        "X_topics = lda_model.fit_transform(x)\n",
        "\n",
        "topic_words = lda_model.components_\n",
        "\n",
        "print(topic_words)\n",
        "print(len(X_topics))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.04075982 0.84946913 0.895772   ... 0.96189213 0.51459884 0.94471675]\n",
            " [1.21622101 0.51704217 0.52082213 ... 0.51298004 0.88051812 0.51176519]]\n",
            "7502\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeSECFACunhF",
        "outputId": "150b2727-c3ce-4463-b07f-97ada990475c"
      },
      "source": [
        "X_topics"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.44899263, 0.55100737],\n",
              "       [0.8390509 , 0.1609491 ],\n",
              "       [0.10909605, 0.89090395],\n",
              "       ...,\n",
              "       [0.85717554, 0.14282446],\n",
              "       [0.81600903, 0.18399097],\n",
              "       [0.15137731, 0.84862269]])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SK2HA5PXyqq6",
        "outputId": "fca5e064-221b-45ed-8ba2-b8ce154b3b0d"
      },
      "source": [
        "X_lr = X_topics\n",
        "Y_lr = df_clean_tfidf['target']\n",
        "X_lr_train, X_lr_test, Y_lr_train, Y_lr_test = train_test_split(X_lr, Y_lr, test_size = 0.2, random_state = 1)\n",
        "clf = LogisticRegression(random_state=1).fit(X_lr_train, Y_lr_train)\n",
        "\n",
        "clf.predict(X_lr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, ..., 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d5FI3MIzgpk",
        "outputId": "1d017f27-cf64-4cb4-d49b-2e3032ee0e1b"
      },
      "source": [
        "clf.score(X_lr_test, Y_lr_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5929380413057961"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKQyzptQ3L63",
        "outputId": "a68c0573-018f-4416-e7da-5ccabc879615"
      },
      "source": [
        "y_pred = clf.predict(X_lr_test)\n",
        "print(sklearn.metrics.classification_report(Y_lr_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.86      0.70       816\n",
            "           1       0.62      0.27      0.38       685\n",
            "\n",
            "    accuracy                           0.59      1501\n",
            "   macro avg       0.60      0.57      0.54      1501\n",
            "weighted avg       0.60      0.59      0.55      1501\n",
            "\n"
          ]
        }
      ]
    }
  ]
}